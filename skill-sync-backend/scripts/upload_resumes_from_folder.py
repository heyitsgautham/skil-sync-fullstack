"""
Upload and populate DB with resumes from the Resumes folder
Creates student accounts and uploads their resumes automatically
"""
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.database.connection import get_db
from app.models.resume import Resume
from app.models.user import User, UserRole
from app.services.parser_service import ResumeParser
from app.services.resume_intelligence_service import ResumeIntelligenceService
from app.services.rag_engine import rag_engine
from app.services.s3_service import s3_service
import time
from datetime import datetime
import traceback
import shutil
from pathlib import Path

# Resume folder path
RESUME_FOLDER = "/Users/gauthamkrishna/Projects/presidio/skill-sync/Resumes"
UPLOAD_DIR = "app/public/resumes"

# API key for Gemini
GEMINI_API_KEY = "AIzaSyA_woTNrFUowjz8R5GLyz9u9TzxzbH9Xl4"

def create_student_from_resume_name(file_name: str, db) -> User:
    """
    Create a student user based on resume filename
    Extracts name from filename (e.g., "Alex Rodriguez.pdf" -> "Alex Rodriguez")
    """
    # Remove file extension
    full_name = os.path.splitext(file_name)[0]
    
    # Generate email from name (e.g., "Alex Rodriguez" -> "alex.rodriguez@example.com")
    email = full_name.lower().replace(" ", ".") + "@example.com"
    
    # Check if user already exists
    existing_user = db.query(User).filter(User.email == email).first()
    if existing_user:
        print(f"   üë§ User already exists: {full_name} ({email})")
        return existing_user
    
    # Create new student user
    new_user = User(
        full_name=full_name,
        email=email,
        hashed_password="$2b$12$dummyhashforautogeneratedusers",  # Placeholder hash
        role=UserRole.student
    )
    
    db.add(new_user)
    db.commit()
    db.refresh(new_user)
    
    print(f"   ‚úÖ Created new student: {full_name} ({email}) [ID: {new_user.id}]")
    return new_user


def upload_and_parse_resume(file_path: str, student_id: int, file_name: str, db):
    """
    Upload and parse a single resume
    """
    try:
        print(f"\n   üìÑ Processing: {file_name}")
        
        # Set API key
        os.environ['GOOGLE_API_KEY'] = GEMINI_API_KEY
        
        # Create upload directory
        os.makedirs(UPLOAD_DIR, exist_ok=True)
        
        # Copy file to upload directory
        destination_path = os.path.join(UPLOAD_DIR, f"{student_id}_{file_name}")
        shutil.copy2(file_path, destination_path)
        print(f"   üíæ Copied to: {destination_path}")
        
        # Upload to S3 if enabled
        s3_key = None
        if s3_service.is_enabled():
            print(f"   ‚òÅÔ∏è  Uploading to S3...")
            s3_key = s3_service.upload_resume(
                file_path=destination_path,
                student_id=student_id,
                file_name=file_name,
                is_tailored=False,
                internship_id=None
            )
            if s3_key:
                print(f"   ‚úÖ S3 Upload successful: {s3_key}")
        
        # Parse resume - extract raw text
        print(f"   üîç Parsing resume...")
        basic_data = ResumeParser.parse_resume(destination_path)
        resume_text = basic_data.get('parsed_content', '')
        print(f"   ‚úÖ Extracted {len(resume_text)} characters")
        
        # Use Gemini for intelligent extraction
        print(f"   üß† Extracting structured data with Gemini...")
        intelligence_service = ResumeIntelligenceService()
        structured_data = intelligence_service.extract_structured_data(resume_text)
        skills = structured_data.get('all_skills', [])
        print(f"   ‚úÖ Extracted {len(skills)} skills")
        
        # Combine data
        parsed_data = {
            **basic_data,
            **structured_data,
            'parsed_content': resume_text
        }
        
        # Deactivate old resumes for this student
        db.query(Resume).filter(
            Resume.student_id == student_id,
            Resume.is_active == 1
        ).update({"is_active": 0})
        
        # Generate embedding
        print(f"   üî¢ Generating embedding...")
        embedding = None
        if resume_text and skills:
            embedding_text = f"{resume_text}\n\nSkills: {', '.join(skills)}"
            embedding = rag_engine.generate_embedding(embedding_text)
            print(f"   ‚úÖ Generated embedding: dimension {len(embedding) if embedding else 0}")
        
        # Create new resume record
        print(f"   üíæ Creating resume record...")
        new_resume = Resume(
            student_id=student_id,
            file_path=destination_path,
            s3_key=s3_key,
            file_name=file_name,
            parsed_content=resume_text,
            parsed_data=structured_data,
            extracted_skills=skills,
            is_active=1,
            is_tailored=0
        )
        
        db.add(new_resume)
        db.flush()
        
        # Store in ChromaDB
        print(f"   üìö Storing in ChromaDB...")
        if resume_text and skills:
            try:
                embedding_id = rag_engine.store_resume_embedding(
                    resume_id=str(new_resume.id),
                    content=resume_text,
                    skills=skills,
                    metadata={
                        "student_id": student_id,
                        "file_name": file_name
                    }
                )
                new_resume.embedding_id = embedding_id
                print(f"   ‚úÖ Indexed in ChromaDB: {embedding_id}")
            except Exception as e:
                print(f"   ‚ö†Ô∏è  ChromaDB indexing failed: {str(e)[:100]}")
        
        db.commit()
        db.refresh(new_resume)
        
        return {
            "status": "success",
            "resume_id": new_resume.id,
            "student_id": student_id,
            "file_name": file_name,
            "skills_count": len(skills)
        }
        
    except Exception as e:
        db.rollback()
        return {
            "status": "error",
            "file_name": file_name,
            "error": str(e)[:500]
        }


def main():
    print("=" * 80)
    print("UPLOAD RESUMES FROM FOLDER")
    print("=" * 80)
    print(f"Start Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"Resume Folder: {RESUME_FOLDER}")
    print()
    
    db = next(get_db())
    
    # Find all PDF files in the Resume folder
    resume_files = []
    if os.path.exists(RESUME_FOLDER):
        for file in os.listdir(RESUME_FOLDER):
            if file.endswith('.pdf'):
                resume_files.append(file)
    else:
        print(f"‚ùå Resume folder not found: {RESUME_FOLDER}")
        return
    
    print(f"üìä Found {len(resume_files)} resume files")
    print()
    
    if len(resume_files) == 0:
        print("‚ùå No resume files found!")
        return
    
    # Statistics
    results = {
        "success": [],
        "error": []
    }
    
    # Process each resume
    for idx, file_name in enumerate(resume_files, 1):
        print(f"\n{'='*80}")
        print(f"üìù Processing Resume {idx}/{len(resume_files)}")
        print(f"{'='*80}")
        
        file_path = os.path.join(RESUME_FOLDER, file_name)
        
        # Create student user from filename
        try:
            student = create_student_from_resume_name(file_name, db)
        except Exception as e:
            print(f"   ‚ùå Failed to create student: {str(e)}")
            results["error"].append({
                "file_name": file_name,
                "error": f"Student creation failed: {str(e)}"
            })
            continue
        
        # Upload and parse resume
        result = upload_and_parse_resume(file_path, student.id, file_name, db)
        
        if result["status"] == "success":
            print(f"   ‚úÖ SUCCESS: Resume uploaded with {result['skills_count']} skills")
            results["success"].append(result)
        else:
            print(f"   ‚ùå ERROR: {result['error']}")
            results["error"].append(result)
        
        # Small delay between requests
        time.sleep(2)
    
    # Print Summary
    print("\n" + "=" * 80)
    print("SUMMARY")
    print("=" * 80)
    print(f"End Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    print(f"‚úÖ Successfully Processed: {len(results['success'])}/{len(resume_files)}")
    print(f"‚ùå Failed: {len(results['error'])}/{len(resume_files)}")
    print()
    
    if results["success"]:
        print("‚úÖ SUCCESSFUL UPLOADS:")
        for r in results["success"]:
            print(f"   - Resume {r['resume_id']}: {r['file_name']} ({r['skills_count']} skills)")
    
    if results["error"]:
        print(f"\n‚ùå FAILED UPLOADS ({len(results['error'])}):")
        for r in results["error"]:
            print(f"   - {r['file_name']}")
            print(f"     Error: {r['error'][:150]}")
    
    print("\n" + "=" * 80)
    
    # Calculate success rate
    success_rate = (len(results['success']) / len(resume_files) * 100) if len(resume_files) > 0 else 0
    print(f"üìä Success Rate: {success_rate:.1f}%")
    
    if success_rate == 100:
        print("üéâ All resumes uploaded successfully!")
    elif success_rate >= 80:
        print("‚úÖ Most resumes uploaded successfully!")
    else:
        print("‚ö†Ô∏è  Many uploads failed. Check errors above.")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Process interrupted by user")
    except Exception as e:
        print(f"\n\n‚ùå Fatal Error: {str(e)}")
        traceback.print_exc()
